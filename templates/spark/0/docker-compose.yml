hadoop-namenode:
  image: uhopper/hadoop-namenode:2.7.2
  labels:
    io.rancher.container.hostname_override: container_name
  volumes:
    - /hadoop/dfs/name
  environment:
    - CLUSTER_NAME=test
    - HDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check=false
    - CORE_CONF_fs_defaultFS=hdfs://hadoop-namenode:8020
  ports:
    - "50070:50070"
    - "8020:8020"

hadoop-datanode:
  image: uhopper/hadoop-datanode:2.7.2
  labels:
    io.rancher.container.hostname_override: container_name
  volumes:
    - /hadoop/dfs/data
  environment:
    - CORE_CONF_fs_defaultFS=hdfs://hadoop-namenode:8020

spark-master:
  image: hfreire/hadoop-spark:1.6.2_2.7.2
  labels:
    io.rancher.container.hostname_override: container_name
  environment:
    - SPARK_LOCAL_IP=0.0.0.0
    - SPARK_PUBLIC_DNS=spark-master
    - CORE_CONF_fs_defaultFS=hdfs://hadoop-namenode:8020
  ports:
      - "8080:8080"
      - "7077:7077"
      - "6066:6066"
  command: master

spark-slave:
  image: hfreire/hadoop-spark:1.6.2_2.7.2
  labels:
    io.rancher.container.hostname_override: container_name
  environment:
    - SPARK_LOCAL_IP=0.0.0.0
    - CORE_CONF_fs_defaultFS=hdfs://hadoop-namenode:8020
    - SPARK_CONF_spark_master=spark://spark-master:7077
  ports:
      - "8081:8081"
  command: slave spark://spark-master:7077
